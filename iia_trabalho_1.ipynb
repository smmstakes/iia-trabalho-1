{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-ivdkvu3xVP",
        "outputId": "97ade310-d936-4c23-beec-760c9678f92f"
      },
      "outputs": [],
      "source": [
        "# # Importa biblioteca para utilização de ferramentas de sistema operacional\n",
        "# import os\n",
        "\n",
        "# # Clona o repositório, com os datasets, se não existir uma versão dele\n",
        "# if not os.path.exists('/content/iia-trabalho-1'):\n",
        "#   !git clone https://github.com/smmstakes/iia-trabalho-1.git\n",
        "\n",
        "# # Instalando biblioteca para geração de dados falsos\n",
        "# !pip install Faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "obrfChP432LC"
      },
      "outputs": [],
      "source": [
        "# Importa todas as bibliotecas a serem utilizadas no projeto\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import unicodedata\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from faker import Faker\n",
        "from geopy.distance import geodesic\n",
        "from geopy.geocoders import Nominatim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en2MJaL2KChy"
      },
      "outputs": [],
      "source": [
        "# # Lista com as cidades dos produtores\n",
        "with open(\"./data/json/cities_list.json\", \"r\") as file:\n",
        "    cities_list = json.load(file)\n",
        "\n",
        "# Dicionário com uma tupla com a localização de cada cidade\n",
        "# locations = get_locations(cities_list)\n",
        "with open(\"./data/json/locations.json\", \"r\") as file:\n",
        "  locations = json.load(file)\n",
        "\n",
        "with open(\"./data/json/producers_locations.json\", \"r\") as file:\n",
        "  producers_location = json.load(file)\n",
        "\n",
        "with open(\"./data/json/producers_ra.json\", \"r\") as file:\n",
        "    producers_ra = json.load(file)\n",
        "\n",
        "# Lista de cada produto ofertado pelos produtores\n",
        "with open(\"./data/json/products_list.json\", \"r\") as file:\n",
        "    products_list = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wbY8YEHTCUG"
      },
      "outputs": [],
      "source": [
        "# Definindo funções auxiliares\n",
        "\n",
        "def get_locations(cities_list: list) -> dict:\n",
        "  # Definindo um agente para pegar as coordenadas\n",
        "  geolocator = Nominatim(user_agent=\"loc_producers\", timeout=10)\n",
        "  locations = {}\n",
        "\n",
        "  for city in cities_list:\n",
        "    try:\n",
        "      time.sleep(1)\n",
        "\n",
        "      # Requisição para uma cidade na lista de cidade\n",
        "      loc = geolocator.geocode(f\"{city}, DF, Brasil\")\n",
        "      locations[city] = (loc.latitude, loc.longitude) if loc else (None, None)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao tentar achar: {city}: {e}\")\n",
        "      locations[city] = (None, None)\n",
        "\n",
        "  return locations\n",
        "\n",
        "def name_formatter(name: str) -> str:\n",
        "    # Remove acentos e normaliza caracteres\n",
        "    new_name = unicodedata.normalize('NFKD', name)\n",
        "\n",
        "    # Substitui espaços por underscores e remove caracteres especiais\n",
        "    return new_name.encode('ascii', 'ignore').decode('ascii').replace(' ', '_')\n",
        "\n",
        "def producer_infos(producer: str) -> tuple:\n",
        "  try:\n",
        "    prod, formatted_local = producer.split(\"_\", 1)\n",
        "\n",
        "    if prod.startswith(\"Rede\"):\n",
        "      return \"Rede Terra\" ,\"Santa Maria\", locations[\"Santa Maria\"][0], locations[\"Santa Maria\"][1]\n",
        "\n",
        "    for city in cities_list:\n",
        "      if name_formatter(city) == formatted_local:\n",
        "        correct_location = city\n",
        "        lat, lon = locations[correct_location]\n",
        "        return prod, correct_location, lat, lon\n",
        "\n",
        "  except ValueError as e:\n",
        "      return \"Desconhecido\", \"Desconhecido\", 0.0, 0.0\n",
        "  \n",
        "def producer_name_formatter(producers: list) -> list:\n",
        "    prods_formatted = []\n",
        "    for producer, locals in producers.items():\n",
        "        for ra in locals:\n",
        "            produtor_formatado = producer.replace(' ', '_')\n",
        "            ra = name_formatter(ra)\n",
        "            prods_formatted.append(f\"{produtor_formatado}_{ra}\")\n",
        "    return prods_formatted\n",
        "\n",
        "def get_distance(coord1, coord2):\n",
        "    return geodesic(coord1, coord2).kilometers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YqSI7SpNICb"
      },
      "outputs": [],
      "source": [
        "# Concatenando nome do produtor com suas RAs\n",
        "\n",
        "# producers_formatted = producer_name_formatter(producers_ra)\n",
        "with open(\"./data/json/producers_formatted.json\", \"r\") as file:\n",
        "    producers_formatted =  json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0itXbWR7i38-"
      },
      "outputs": [],
      "source": [
        "# Definindo número inicial para geração pseudo-aleatória\n",
        "np.random.seed(53)\n",
        "\n",
        "matrix_size = 2000\n",
        "\n",
        "# Base do DataFrame de produtos\n",
        "products = {\n",
        "    \"produto\": [],\n",
        "    \"organico\": [],\n",
        "    \"nome_produtor\": [],\n",
        "    \"local\": [],\n",
        "    \"latitude\": [],\n",
        "    \"longitude\": []\n",
        "}\n",
        "\n",
        "# Adicionando informações sobre produtos vendidos por cada produtor\n",
        "for _ in range(matrix_size):\n",
        "    products[\"produto\"].append(np.random.choice(products_list))\n",
        "    products[\"organico\"].append(np.random.choice([0, 1]))\n",
        "\n",
        "    prod = np.random.choice(producers_formatted)\n",
        "    producer, local, lat, lon = producer_infos(prod)\n",
        "\n",
        "    products[\"nome_produtor\"].append(producer)\n",
        "    products[\"local\"].append(local)\n",
        "    products[\"latitude\"].append(lat)\n",
        "    products[\"longitude\"].append(lon)\n",
        "\n",
        "# Gerando DataFrame e exportando para csv\n",
        "df_products = pd.DataFrame(products).drop_duplicates()\n",
        "df_products.to_csv('./data/datasets/producers.csv', index=False)\n",
        "df_products.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKGb_ao2VDze"
      },
      "outputs": [],
      "source": [
        "# Gerador de dados falsos\n",
        "fake = Faker()\n",
        "\n",
        "n_reviews = 7500\n",
        "n_users = 2500\n",
        "\n",
        "# Criando usuários ficticios\n",
        "users = [fake.uuid4() for _ in range(n_users)]\n",
        "\n",
        "# Basa para o DataFrame de avaliação de produtos\n",
        "reviews = {\n",
        "          \"id_usuario\": [],\n",
        "          \"produto\": [],\n",
        "          \"organico\": [],\n",
        "          \"nome_produtor\": [],\n",
        "          \"local\": [],\n",
        "          \"avaliacao\": []\n",
        "        }\n",
        "\n",
        "for _ in range(n_reviews):\n",
        "  reviews[\"id_usuario\"].append(np.random.choice(users))\n",
        "\n",
        "  id_produto = np.random.choice(len(df_products))\n",
        "\n",
        "  reviews[\"produto\"].append(df_products.iloc[id_produto][\"produto\"])\n",
        "  reviews[\"organico\"].append(df_products.iloc[id_produto][\"organico\"])\n",
        "  reviews[\"nome_produtor\"].append(df_products.iloc[id_produto][\"nome_produtor\"])\n",
        "  reviews[\"local\"].append(df_products.iloc[id_produto][\"local\"])\n",
        "  reviews[\"avaliacao\"].append(np.random.randint(1, 6))\n",
        "\n",
        "df_reviews = pd.DataFrame(reviews).drop_duplicates()\n",
        "df_reviews.to_csv('./data/datasets/reviews.csv', index=False)\n",
        "df_reviews.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhChlJoLOfLL"
      },
      "outputs": [],
      "source": [
        "utility_matrix = pd.pivot_table(\n",
        "  df_reviews,\n",
        "  values='avaliacao',\n",
        "  index='nome_produtor',\n",
        "  columns='produto',\n",
        "  fill_value=0\n",
        "  ).round(2)\n",
        "\n",
        "utility_matrix.to_csv('./data/datasets/matrix_reviews.csv')\n",
        "utility_matrix.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX5tH89tLptw"
      },
      "outputs": [],
      "source": [
        "# Juntando os dados para formar uma base de recomendação\n",
        "\n",
        "# 1. Juntar as avaliações com os dados dos produtores\n",
        "df_full_reviews = df_reviews.merge(df_products, on=[\"nome_produtor\", \"produto\", \"organico\", \"local\"], how=\"inner\")\n",
        "\n",
        "df_full_reviews.to_csv(\"./data/datasets/df_full_reviews.csv\", index=False)\n",
        "\n",
        "# Inicializar encoders\n",
        "le_usuario = LabelEncoder()\n",
        "le_produto = LabelEncoder()\n",
        "le_produtor = LabelEncoder()\n",
        "le_local = LabelEncoder()\n",
        "\n",
        "# Codificar colunas categóricas\n",
        "df_full_reviews[\"usuario_id\"] = le_usuario.fit_transform(df_full_reviews[\"id_usuario\"])\n",
        "df_full_reviews[\"produto_id\"] = le_produto.fit_transform(df_full_reviews[\"produto\"])\n",
        "df_full_reviews[\"produtor_id\"] = le_produtor.fit_transform(df_full_reviews[\"nome_produtor\"])\n",
        "df_full_reviews[\"local_id\"] = le_local.fit_transform(df_full_reviews[\"local\"])\n",
        "\n",
        "df_full_reviews[[\"usuario_id\", \"produto_id\", \"organico\", \"avaliacao\", \"produtor_id\", \"local_id\", \"latitude\", \"longitude\"]].head(20)\n",
        "\n",
        "# Features usadas para similaridade (excluindo avaliação que será alvo)\n",
        "feature_cols = [\"produto_id\", \"organico\", \"produtor_id\", \"local_id\", \"latitude\", \"longitude\"]\n",
        "\n",
        "# Matriz de características e vetor de alvo\n",
        "X = df_full_reviews[feature_cols].values\n",
        "y = df_full_reviews['avaliacao'].values\n",
        "\n",
        "# Modelo de vizinhos mais próximos\n",
        "knn_model = NearestNeighbors(n_neighbors=6, metric='euclidean')\n",
        "knn_model.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_recommendation_candidates(desired_products, producer, location):\n",
        "    # global df_full_reviews\n",
        "\n",
        "    if isinstance(desired_products, str):\n",
        "        desired_products = [desired_products]\n",
        "\n",
        "    candidates = df_full_reviews[\n",
        "        (df_full_reviews['produto'].isin(desired_products)) |\n",
        "        (df_full_reviews['nome_produtor'] == producer) |\n",
        "        (df_full_reviews['local'] == location)\n",
        "    ].copy()\n",
        "\n",
        "    # Remove combinações exatas\n",
        "    candidates = candidates[~(\n",
        "        (candidates['produto'].isin(desired_products)) &\n",
        "        (candidates['nome_produtor'] == producer) |\n",
        "        (candidates['produto'].isin(desired_products))\n",
        "    )]\n",
        "\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def normalize_distance(candidates, latitude, longitude):\n",
        "    candidates['distancia_km'] = candidates.apply(\n",
        "        lambda row: get_distance((latitude, longitude), (row['latitude'], row['longitude'])),\n",
        "        axis=1\n",
        "    )\n",
        "    max_dist = candidates['distancia_km'].max()\n",
        "    candidates['proximidade'] = 1 - (candidates['distancia_km'] / max_dist)\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def calculate_average_rating(candidates):\n",
        "    candidates['media_produtor_produto'] = (\n",
        "        candidates.groupby(['produto', 'nome_produtor'])['avaliacao']\n",
        "        .transform('mean')\n",
        "    )\n",
        "    candidates['avaliacao_norm'] = candidates['media_produtor_produto'] / 5.0\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def calculate_score(recommendation_type: int, is_organic: int, feature_values: list) -> float:\n",
        "    # Inicialização dos pesos padrão\n",
        "    weights = {\n",
        "        \"rating\": 0.5,\n",
        "        \"proximity\": 0.5,\n",
        "        \"organic\": 0.0\n",
        "    }\n",
        "\n",
        "    if recommendation_type in (0, 2):\n",
        "        if is_organic == 1:\n",
        "            weights.update({\n",
        "                \"rating\": 0.3,\n",
        "                \"proximity\": 0.5,\n",
        "                \"organic\": 0.2\n",
        "            })\n",
        "        else:\n",
        "            weights[\"organic\"] = -1.0\n",
        "\n",
        "    elif recommendation_type == 1:\n",
        "        weights.update({\n",
        "            \"rating\": 0.7,\n",
        "            \"proximity\": 0.3,\n",
        "            \"organic\": 0.0\n",
        "        })\n",
        "        # Para tipo 1, só rating e proximidade são usados\n",
        "        return (\n",
        "            weights[\"rating\"] * feature_values[0]\n",
        "            + weights[\"proximity\"] * feature_values[1]\n",
        "        )\n",
        "\n",
        "    # Cálculo do score final para tipos 0 e 2\n",
        "    return (\n",
        "        weights[\"rating\"] * feature_values[0]\n",
        "        + weights[\"proximity\"] * feature_values[1]\n",
        "        + weights[\"organic\"] * feature_values[2]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_n7fyG6e725"
      },
      "outputs": [],
      "source": [
        "def recommend_best_products(desired_products, producer, location, organic, latitude, longitude):\n",
        "    candidates = get_recommendation_candidates(desired_products, producer, location)\n",
        "\n",
        "    if candidates.empty:\n",
        "        return pd.DataFrame({'mensagem': ['Nenhuma recomendação alternativa encontrada.']})\n",
        "\n",
        "    candidates = normalize_distance(candidates, latitude, longitude)\n",
        "    candidates = calculate_average_rating(candidates)\n",
        "\n",
        "    features_values = [candidates['avaliacao_norm'], candidates['proximidade'], candidates['organico']]\n",
        "    candidates[\"score\"] = calculate_score(0, organic, features_values)\n",
        "\n",
        "    top_recommendations = (\n",
        "        candidates.sort_values(by='score', ascending=False)\n",
        "        .drop_duplicates(subset=['produto', 'nome_produtor'])\n",
        "        .head(5)\n",
        "    )\n",
        "\n",
        "    return top_recommendations[[\n",
        "        'produto', 'nome_produtor', 'local', 'organico',\n",
        "        'media_produtor_produto', 'distancia_km', 'score'\n",
        "    ]].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-JWhjhJve-Z0",
        "outputId": "688cf883-691b-4e65-fa0a-b0fcc988425a"
      },
      "outputs": [],
      "source": [
        "# Recomenda os melhores produtos de determinado produtor com base no produto fornecido e se é organico\n",
        "recommend_best_products(\n",
        "    desired_products=['Uva', \"Limão\"],\n",
        "    producer='Asphor',\n",
        "    location='Gama',\n",
        "    organic=0,\n",
        "    latitude=-16.0170857,\n",
        "    longitude=-48.0653054\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_producer_recomendation(df_reviews, product):\n",
        "    candidates = df_reviews[df_reviews['produto'] == product].copy()\n",
        "\n",
        "    if product.strip() == \"\":\n",
        "        candidates = df_reviews.copy()\n",
        "\n",
        "    if candidates.empty:\n",
        "        return pd.DataFrame({'mensagem': ['Nenhum produtor encontrado para este produto.']})\n",
        "    \n",
        "    # candidates = candidates.sort_values('media_avaliacao', ascending=False)\n",
        "    return candidates.drop_duplicates(subset=['nome_produtor'], keep='first')\n",
        "\n",
        "def calculate_average_producer_rating(candidates):\n",
        "    candidates = (\n",
        "        candidates.groupby(['nome_produtor', 'local', 'latitude', 'longitude', 'organico'])\n",
        "        .agg(media_avaliacao=('avaliacao', 'mean'))\n",
        "        .reset_index()\n",
        "    )\n",
        "    candidates['avaliacao_norm'] = candidates['media_avaliacao'] / 5.0\n",
        "    return candidates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend_best_productors(product, latitude, longitude, top_n=5):\n",
        "    candidates = get_producer_recomendation(df_full_reviews, product)\n",
        "    candidates = calculate_average_producer_rating(candidates)\n",
        "    candidates = normalize_distance(candidates, latitude, longitude)\n",
        "\n",
        "    features_values = [candidates['avaliacao_norm'], candidates['proximidade'], candidates[\"organico\"]]\n",
        "    candidates[\"score\"] = calculate_score(1, 0, features_values)\n",
        "\n",
        "    top_result = candidates.sort_values(by='score', ascending=False).head(top_n)\n",
        "\n",
        "    return top_result[[\n",
        "        'nome_produtor', 'local', 'organico',\n",
        "        'media_avaliacao', 'distancia_km', 'score'\n",
        "    ]].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recomenda os melhores produtores de determinado produto considerando a localização como foco\n",
        "recommend_best_productors(\n",
        "    product='Maracujá',\n",
        "    latitude=-15.7183687,\n",
        "    longitude=-47.9950273\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_products_recomendation(df_full_reviews, producer, unwanted_products):\n",
        "    if unwanted_products is None:\n",
        "        unwanted_products = []\n",
        "\n",
        "    candidates = df_full_reviews[\n",
        "        (df_full_reviews['nome_produtor'] == producer) &\n",
        "        (~df_full_reviews['produto'].isin(unwanted_products))\n",
        "    ].copy()\n",
        "\n",
        "    if candidates.empty:\n",
        "        return pd.DataFrame({'mensagem': ['Nenhum produtor encontrado para este produto.']})\n",
        "    \n",
        "    return candidates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkx6bOx4pL2x"
      },
      "outputs": [],
      "source": [
        "def recommend_best_product_productors(producer, local, organic, latitude, longitude, unwanted_products=None):\n",
        "\n",
        "    candidates = get_products_recomendation(df_full_reviews, producer, unwanted_products)\n",
        "    candidates = normalize_distance(candidates, latitude, longitude)\n",
        "    candidates = candidates.drop_duplicates(subset=['produto', 'nome_produtor'])\n",
        "    candidates = calculate_average_rating(candidates)\n",
        "\n",
        "    features_values = [candidates['avaliacao_norm'], candidates['proximidade'], candidates['organico']]\n",
        "    candidates[\"score\"] = calculate_score(2, organic, features_values)\n",
        "    \n",
        "    resultado = candidates.sort_values(by='score', ascending=False).head(5)\n",
        "\n",
        "    return resultado[['produto', 'nome_produtor', 'local', 'organico',\n",
        "                      'media_produtor_produto', 'distancia_km', 'score']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QNw0f20bpOvw",
        "outputId": "a0e81370-0b26-46e4-d361-87c602eb05b9"
      },
      "outputs": [],
      "source": [
        "# Recomenda os melhores produtos de um determinado produtor\n",
        "\n",
        "recommend_best_product_productors(\n",
        "    producer='Cooperbrasília',\n",
        "    local='Gama',\n",
        "    organic=0,\n",
        "    latitude=-15.650053,\n",
        "    longitude=-47.784845,\n",
        "    unwanted_products=[\"Mandioca\", \"Morango\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_data = {\n",
        "    \"model\": knn_model\n",
        "}\n",
        "\n",
        "with open(\"./data/model/model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(full_data, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
